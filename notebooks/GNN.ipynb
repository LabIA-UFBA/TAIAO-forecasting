{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92391c9b-ffda-4cc3-bd0c-20d0ab4767d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# pre processing\n",
    "from sklearn import preprocessing as pre\n",
    "# NN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool\n",
    "# val and plot\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    median_absolute_error,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from loguru import logger as log\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data\n",
    "from torchviz import make_dot\n",
    "from tqdm.notebook import trange  # opcional, pra barra de progresso\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, LEConv, GlobalAttention\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca496da4-4d19-473c-a157-80ef07fc99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "SEED = 1345\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(SEED)\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.float_format', '{:.16f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50be195-9e30-4092-be6a-928b200f6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fpath):\n",
    "    # Load the StaticGraphTemporalSignal object from the file\n",
    "    with open(fpath, 'rb') as f:\n",
    "        loaded_temporal_signal = pickle.load(f)\n",
    "    return loaded_temporal_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1d0306-1ebb-44ef-86a5-45ec8b9cee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06155ce-f87f-4014-b079-c5890954736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(f'dataset_train_{c}_time_sts.pkl')\n",
    "test_dataset = load_dataset(f'dataset_test_{c}_time_sts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4aff2b-c68d-4516-a47e-1cf164fa9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GlobalAttention, JumpingKnowledge\n",
    "# opcional: GraphNorm funciona bem quando há batchs grandes\n",
    "# from torch_geometric.nn import GraphNorm\n",
    "\n",
    "class GraphSAGEForecast(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, horizon=100, out_dims=3,\n",
    "                 num_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.out_dims = out_dims\n",
    "        self.dropout_p = dropout\n",
    "\n",
    "        # ----- Encoder GNN -----\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.norms.append(nn.LayerNorm(hidden_channels))  # GraphNorm se preferir\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.norms.append(nn.LayerNorm(hidden_channels))\n",
    "\n",
    "        # Jumping Knowledge para combinar representações de todas as camadas\n",
    "        self.jk = JumpingKnowledge(mode='cat')\n",
    "        self.proj_jk = nn.Linear(hidden_channels * num_layers, hidden_channels)\n",
    "\n",
    "        # Gating mais expressivo para a atenção global\n",
    "        self.pool = GlobalAttention(\n",
    "            gate_nn=nn.Sequential(\n",
    "                nn.Linear(hidden_channels, hidden_channels // 2),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_channels // 2, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # ----- Decoder p/ horizonte -----\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 2 * hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2 * hidden_channels, self.out_dims * self.horizon)\n",
    "        )\n",
    "\n",
    "        # init um pouco melhor p/ lineares\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        if batch is None:\n",
    "            # se vier um único grafo, crie um batch “fake”\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "        xs = []\n",
    "        h = x\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            h_res = h\n",
    "            h = conv(h, edge_index)\n",
    "            h = norm(h)\n",
    "            h = F.gelu(h)\n",
    "            h = self.dropout(h)\n",
    "            # pequeno residual ajuda estabilidade (não mudar dims!)\n",
    "            h = h + h_res if h.shape == h_res.shape else h\n",
    "            xs.append(h)\n",
    "\n",
    "        h = self.jk(xs)          # [num_nodes_total, hidden * num_layers]\n",
    "        h = F.gelu(self.proj_jk(h))\n",
    "        g = self.pool(h, batch)   # [B, hidden]\n",
    "\n",
    "        out = self.decoder(g)     # [B, 3*horizon]\n",
    "        out = out.view(g.size(0), self.out_dims, self.horizon)  # [B, 3, H]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866927fa-8f01-431a-8bb0-89c03892dd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:2'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f0b5e8-4675-4e22-829d-44e4eb98dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGEForecast(\n",
    "    in_channels=100,\n",
    "    hidden_channels=128,\n",
    "    horizon=100,      # 100 passos à frente\n",
    "    out_dims=1,       # 3 dimensões no espaço de fase\n",
    "    num_layers=3,\n",
    "    dropout=0.2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb980b1-27e7-42b4-8bb8-89b6c61ca5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_loss(y_pred, y_true, lam_smooth=0.1):\n",
    "    # garante batch dimension quando vier 2D\n",
    "    if y_pred.dim() == 2:\n",
    "        y_pred = y_pred.unsqueeze(0)   # [1, 3, H]\n",
    "    if y_true.dim() == 2:\n",
    "        y_true = y_true.unsqueeze(0)   # [1, 3, H]\n",
    "\n",
    "    # MSE básico\n",
    "    base = F.mse_loss(y_pred, y_true)\n",
    "\n",
    "    # termo de suavidade temporal (diferenças finitas)\n",
    "    dp = y_pred[:, :, 1:] - y_pred[:, :, :-1]\n",
    "    dt = y_true[:, :, 1:] - y_true[:, :, :-1]\n",
    "    smooth = F.mse_loss(dp, dt)\n",
    "\n",
    "    return base + lam_smooth * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b7e4a8c-0d17-49e1-9af3-df4bbeaa4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphTemporalModel(\n",
    "#     node_features=100,  # conforme seu x=[12, 100]\n",
    "#     horizon=100,\n",
    "#     num_targets=3\n",
    "# ).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25cf9f72-ce5f-4162-b02b-f9cb052e3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.targets = [\n",
    "    t.detach().cpu().numpy() if isinstance(t, torch.Tensor) else t\n",
    "    for t in train_dataset.targets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a4dcb3-305f-442b-ba78-eb71bfb93d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.7500\n",
      "Epoch 59, Train Loss: 0.7418\n",
      "Epoch 89, Train Loss: 0.7354\n",
      "Epoch 119, Train Loss: 0.7334\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "# for epoch in tqdm(range(100)):\n",
    "#     model.train()\n",
    "#     cost = 0\n",
    "#     h, c = None, None\n",
    "#     for time, snapshot in enumerate(train_dataset): # faz o treino em cada bath temporal\n",
    "#         snapshot.to(device)\n",
    "#         y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "#         #print(f\"y_hat: {y_hat.shape} snapshot: {snapshot.y.shape}\")\n",
    "#         cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "        \n",
    "nb_epocas = 120\n",
    "for epoch in range(nb_epocas):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for snapshot in train_dataset:\n",
    "        snapshot = snapshot.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index)\n",
    "        #loss = torch.mean((y_hat - snapshot.y)**2)\n",
    "        loss = trajectory_loss(y_hat, snapshot.y, lam_smooth=0.1)\n",
    "        #loss = F.mse_loss(y_hat, snapshot.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        training_loss.append(train_loss)\n",
    "    if (epoch+1) % 30 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss/train_dataset.snapshot_count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e84f46-1371-42b9-adc5-6491430d9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataset, device):\n",
    "    model.eval()  # Modo de avaliação (desativa dropout, batchnorm, etc.)\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    with torch.no_grad():  # Desativa cálculo de gradientes (economiza memória)\n",
    "        for time, snapshot in enumerate(test_dataset):\n",
    "            snapshot = snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index)  # Forward pass\n",
    "            loss = torch.mean((y_hat - snapshot.y)**2)  # MSE\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Guarda previsões e valores reais para métricas adicionais\n",
    "            predictions.append(y_hat.cpu().numpy())\n",
    "            ground_truths.append(snapshot.y.cpu().numpy())\n",
    "\n",
    "    # Calcula a média do erro sobre todos os snapshots\n",
    "    test_loss /= test_dataset.snapshot_count\n",
    "    print(f\"\\nTest Loss (MSE): {test_loss:.4f}\")\n",
    "\n",
    "    # Converte listas para arrays numpy (opcional, útil para análise)\n",
    "    predictions = np.stack(predictions)\n",
    "    ground_truths = np.stack(ground_truths)\n",
    "\n",
    "    return test_loss, predictions, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9689423e-e7ee-4e8a-a47e-5bdd51f54560",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.targets = [\n",
    "    t.detach().cpu().numpy() if isinstance(t, torch.Tensor) else t\n",
    "    for t in test_dataset.targets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90e4fa5-b5e1-4b64-8a24-e80705d8cf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss (MSE): 0.3396\n"
     ]
    }
   ],
   "source": [
    "test_loss, y_pred, y_true = test(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0cd7d0-481c-4ffa-b31a-c99db9c2821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_src = y_pred.copy()\n",
    "y_true_src = y_true.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53006d68-9d1a-41dd-9736-c5b08db08dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 1, 1, 100), (300, 51, 100))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_src.shape, y_true_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb672c9a-7026-4da8-a781-8ced87239864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape idx: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape idx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true_src[idx,\u001b[38;5;241m2\u001b[39m,:]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43my_pred_src\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m ytrues\u001b[38;5;241m.\u001b[39mextend(y_true)\n\u001b[1;32m     12\u001b[0m ypreds\u001b[38;5;241m.\u001b[39mextend(y_pred)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "ytrues = []\n",
    "ypreds = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"shape idx: {idx}\")\n",
    "    y_true = y_true_src[idx,2,:].tolist()\n",
    "    y_pred = y_pred_src[idx,2,:].tolist()\n",
    "    \n",
    "    ytrues.extend(y_true)\n",
    "    ypreds.extend(y_pred)\n",
    "    \n",
    "    idx += 100\n",
    "    if idx == 100:\n",
    "        idx -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f39b5-dd15-418a-90af-15131b83a82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
